{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN8421XMc6TWNussYqBoqBa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michila0/pose-detection/blob/main/VedioConvertImages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AGqIrA0VHfCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload the Video to Google Colab"
      ],
      "metadata": {
        "id": "UuEqdmqMomrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "hMfjYmL-okZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Required Libraries"
      ],
      "metadata": {
        "id": "BrgHZGQ_qT6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "1bYAzSG4oXyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Frames from the Video"
      ],
      "metadata": {
        "id": "w3b6aQ31qXuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6C5VnYDnAFT"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the video\n",
        "video_path = list(uploaded.keys())[0]  # Get the uploaded video file name\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Create a folder to save extracted images\n",
        "image_save_folder = \"extracted_images\"\n",
        "if not os.path.exists(image_save_folder):\n",
        "    os.makedirs(image_save_folder)\n",
        "\n",
        "# Extract frames\n",
        "frame_count = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save every nth frame\n",
        "    if frame_count % 1 == 0:\n",
        "        image_path = os.path.join(image_save_folder, f\"frame_{frame_count}.jpg\")\n",
        "        cv2.imwrite(image_path, frame)\n",
        "        print(f\"Saved {image_path}\")\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "print(f\"Extracted {frame_count} frames.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  View Extracted Images"
      ],
      "metadata": {
        "id": "dHvnJBb9vh0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# List all extracted images\n",
        "image_files = os.listdir(image_save_folder)\n",
        "\n",
        "# Display the first few images\n",
        "for i, image_file in enumerate(image_files[:5]):  # Display first 5 images\n",
        "    image_path = os.path.join(image_save_folder, image_file)\n",
        "    image = cv2.imread(image_path)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(image_file)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CK9a60tLvnjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pose Estimation + Motion Analysis\n",
        "This method uses pose estimation to track the batsman's body joints and analyzes their motion to detect batting actions."
      ],
      "metadata": {
        "id": "wam2uXpdqyvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libaries"
      ],
      "metadata": {
        "id": "C9ottF0prrpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python numpy matplotlib"
      ],
      "metadata": {
        "id": "qAyUSoXpsQVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect Batting Pose with MediaPipe\n",
        "Use MediaPipe to track the batsman's body joints(e.g: arms, shoulders, wrists) and analyze their movement over time.\n"
      ],
      "metadata": {
        "id": "Z91so0xgsvvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Initialize MediaPipe Pose\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
        "\n",
        "# Process frames from the extracted images folder\n",
        "image_save_folder = \"extracted_images\"\n",
        "image_files = sorted(os.listdir(image_save_folder))\n",
        "\n",
        "# Store joint angles or positions\n",
        "batting_frames = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_save_folder, image_file)\n",
        "    frame = cv2.imread(image_path)\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Detect pose\n",
        "    results = pose.process(frame_rgb)\n",
        "\n",
        "    if results.pose_landmarks:\n",
        "        # Extract key joints (e.g., right wrist, left wrist, shoulders)\n",
        "        landmarks = results.pose_landmarks.landmark\n",
        "        right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
        "                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
        "        left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
        "                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
        "\n",
        "        # Calculate bat swing angle (example logic)\n",
        "        angle = np.arctan2(right_wrist[1] - left_wrist[1], right_wrist[0] - left_wrist[0])\n",
        "\n",
        "        # Detect swing (threshold-based)\n",
        "        if abs(angle) > 1.5:  # Adjust based on your video\n",
        "            batting_frames.append(image_file)\n",
        "            print(f\"Batting action detected in {image_file}\")\n",
        "\n",
        "pose.close()"
      ],
      "metadata": {
        "id": "ri4wmdFRtUFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Batting Action\n",
        "Plot frames where batting is detected:"
      ],
      "metadata": {
        "id": "hl5TMSuqwZ7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batting_frame in batting_frames[:3]:  # Show first 3 detected frames\n",
        "    image_path = os.path.join(image_save_folder, batting_frame)\n",
        "    image = cv2.imread(image_path)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Batting Action\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZEOmt5TcwqME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Action Recognition\n",
        "Use a pre-trained action recognition model to classify batting actions in short video clips."
      ],
      "metadata": {
        "id": "hp5wLvPxxYBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install MMAction2 (Action Recognition Library)"
      ],
      "metadata": {
        "id": "u9YulLMSxnAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MMAction2 and dependencies\n",
        "!pip install mmcv-full\n",
        "!pip install mmaction2"
      ],
      "metadata": {
        "id": "1qmB_Du9x1PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a Pre-Trained Model\n",
        "Use a model like **SlowFast** or **I3D** for action recognition:"
      ],
      "metadata": {
        "id": "dNFUN0EByN4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mmaction.apis import inference_recognizer, init_recognizer\n",
        "\n",
        "# Load the SlowFast model (pre-trained on Kinetics-400)\n",
        "config_file = 'configs/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb.py'\n",
        "checkpoint_file = 'https://download.openmmlab.com/mmaction/recognition/slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb/slowfast_r50_4x16x1_256e_kinetics400_rgb_20200704-bcde7ed7.pth'\n",
        "model = init_recognizer(config_file, checkpoint_file, device='cuda:0')"
      ],
      "metadata": {
        "id": "2kcAF8_gzSd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify Batting Action\n",
        "Convert your frames into a video clip and run inference:"
      ],
      "metadata": {
        "id": "OyioFWU00IQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Predict action for a clip\n",
        "video_path = '/content/Copy of Cover Drive00000000 (2).mp4'  # Use your video\n",
        "results = inference_recognizer(model, video_path)\n",
        "\n",
        "# Print top-5 predicted actions\n",
        "print(results)"
      ],
      "metadata": {
        "id": "HOjdMYtO0X81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Object Detection\n",
        "Use YOLO to detect the bat and player, then track the batâ€™s motion to identify swings."
      ],
      "metadata": {
        "id": "XwAL4orS4bEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install YOLOv5"
      ],
      "metadata": {
        "id": "0xCQjfXT93yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!pip install -r yolov5/requirements.txt"
      ],
      "metadata": {
        "id": "HWzHDmlT4kul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect Bat and Player"
      ],
      "metadata": {
        "id": "PvUtheMu988m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Detect objects in frames\n",
        "bat_frames = []\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_save_folder, image_file)\n",
        "    results = model(image_path)\n",
        "\n",
        "    # Check if \"bat\" or \"sports ball\" is detected\n",
        "    if 'sports ball' in results.pandas().xyxy[0]['name'].values:\n",
        "        bat_frames.append(image_file)\n",
        "        print(f\"Bat detected in {image_file}\")"
      ],
      "metadata": {
        "id": "SJP_CGFy4nXn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}