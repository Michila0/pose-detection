{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPkzzoAVznt83ZaPe9s8yXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Michila0/pose-detection/blob/main/VedioConvertImages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AGqIrA0VHfCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload the Video to Google Colab"
      ],
      "metadata": {
        "id": "UuEqdmqMomrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "hMfjYmL-okZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Required Libraries"
      ],
      "metadata": {
        "id": "BrgHZGQ_qT6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "1bYAzSG4oXyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Frames from the Video"
      ],
      "metadata": {
        "id": "w3b6aQ31qXuc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6C5VnYDnAFT"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the video\n",
        "video_path = list(uploaded.keys())[0]  # Get the uploaded video file name\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Create a folder to save extracted images\n",
        "image_save_folder = \"extracted_images\"\n",
        "if not os.path.exists(image_save_folder):\n",
        "    os.makedirs(image_save_folder)\n",
        "\n",
        "# Extract frames\n",
        "frame_count = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save every nth frame\n",
        "    if frame_count % 1 == 0:\n",
        "        image_path = os.path.join(image_save_folder, f\"frame_{frame_count}.jpg\")\n",
        "        cv2.imwrite(image_path, frame)\n",
        "        print(f\"Saved {image_path}\")\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "print(f\"Extracted {frame_count} frames.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  View Extracted Images"
      ],
      "metadata": {
        "id": "dHvnJBb9vh0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# List all extracted images\n",
        "image_files = os.listdir(image_save_folder)\n",
        "\n",
        "# Display the first few images\n",
        "for i, image_file in enumerate(image_files[:5]):  # Display first 5 images\n",
        "    image_path = os.path.join(image_save_folder, image_file)\n",
        "    image = cv2.imread(image_path)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(image_file)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CK9a60tLvnjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Track the Ball"
      ],
      "metadata": {
        "id": "39pEcSugtTx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the ultralytics package\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "6W1iCLH4vFoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv8 model (pre-trained on a custom dataset for cricket ball detection)\n",
        "model = YOLO(\"yolov8n.pt\")  # Replace with a custom-trained model if available\n",
        "\n",
        "# Variables to track ball state\n",
        "ball_in_hand = False\n",
        "ball_released = False\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Perform object detection using YOLOv8\n",
        "    results = model(frame)\n",
        "\n",
        "    # Loop through detected objects\n",
        "    for result in results:\n",
        "        boxes = result.boxes.xyxy  # Bounding box coordinates\n",
        "        confidences = result.boxes.conf  # Confidence scores\n",
        "        class_ids = result.boxes.cls  # Class IDs\n",
        "\n",
        "        for box, conf, cls_id in zip(boxes, confidences, class_ids):\n",
        "            if model.names[int(cls_id)] == \"cricket_ball\":  # Check if the detected object is a cricket ball\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Draw bounding box\n",
        "\n",
        "                # Check if the ball is in the bowler's hand (based on position)\n",
        "                if y1 > 100:  # Adjust this condition based on your video\n",
        "                    ball_in_hand = True\n",
        "                    cv2.putText(frame, \"Ball in Hand\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "                else:\n",
        "                    if ball_in_hand:  # Ball was in hand and now released\n",
        "                        ball_released = True\n",
        "                        cv2.putText(frame, \"Ball Released\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow(\"Cricket Ball Tracking\", frame)\n",
        "\n",
        "    # Exit on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break"
      ],
      "metadata": {
        "id": "9Ihr7l4stWil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pose Estimation + Motion Analysis\n",
        "This method uses pose estimation to track the batsman's body joints and analyzes their motion to detect batting actions."
      ],
      "metadata": {
        "id": "wam2uXpdqyvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libaries"
      ],
      "metadata": {
        "id": "C9ottF0prrpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python numpy matplotlib"
      ],
      "metadata": {
        "id": "qAyUSoXpsQVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall mediapipe -y # uninstall existing mediapipe\n",
        "!pip install mediapipe==0.10.20 # install specific version"
      ],
      "metadata": {
        "id": "lJ_BvYhJja_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect Batting Pose with MediaPipe\n",
        "Use MediaPipe to track the batsman's body joints(e.g: arms, shoulders, wrists) and analyze their movement over time.\n"
      ],
      "metadata": {
        "id": "Z91so0xgsvvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "#Initialize MediaPipe Pose\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
        "\n",
        "# Process frames from the extracted images folder\n",
        "image_save_folder = \"extracted_images\"\n",
        "image_files = sorted(os.listdir(image_save_folder))\n",
        "\n",
        "# Store joint angles or positions\n",
        "batting_frames = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_save_folder, image_file)\n",
        "    frame = cv2.imread(image_path)\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Detect pose\n",
        "    results = pose.process(frame_rgb)\n",
        "\n",
        "    if results.pose_landmarks:\n",
        "        # Extract key joints (e.g., right wrist, left wrist, shoulders)\n",
        "        landmarks = results.pose_landmarks.landmark\n",
        "        right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
        "                       landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
        "        left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
        "                      landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
        "\n",
        "        # Calculate bat swing angle (example logic)\n",
        "        angle = np.arctan2(right_wrist[1] - left_wrist[1], right_wrist[0] - left_wrist[0])\n",
        "\n",
        "        # Detect swing (threshold-based)\n",
        "        if abs(angle) > 1.5:  # Adjust based on your video\n",
        "            batting_frames.append(image_file)\n",
        "            print(f\"Batting action detected in {image_file}\")\n",
        "\n",
        "pose.close()"
      ],
      "metadata": {
        "id": "ri4wmdFRtUFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Batting Action\n",
        "Plot frames where batting is detected:"
      ],
      "metadata": {
        "id": "hl5TMSuqwZ7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batting_frame in batting_frames[:10]:  # Show first 3 detected frames\n",
        "    image_path = os.path.join(image_save_folder, batting_frame)\n",
        "    image = cv2.imread(image_path)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Batting Action\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZEOmt5TcwqME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Full Code for Batting Classification"
      ],
      "metadata": {
        "id": "UH4Kn5zEkn1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python numpy matplotlib"
      ],
      "metadata": {
        "id": "BRvlgI7mi0H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize MediaPipe Pose\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
        "\n",
        "# Define shot classification rules\n",
        "def classify_shot(landmarks):\n",
        "    # Extract key landmarks\n",
        "    left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
        "    right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
        "    left_wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
        "    right_wrist = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value]\n",
        "    left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value]\n",
        "    right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value]\n",
        "\n",
        "    # Calculate bat angle (between wrists)\n",
        "    bat_angle = np.arctan2(\n",
        "        right_wrist.y - left_wrist.y,\n",
        "        right_wrist.x - left_wrist.x\n",
        "    )\n",
        "\n",
        "    # Calculate shoulder-hip alignment (front/back foot)\n",
        "    shoulder_hip_diff = abs(left_shoulder.y - right_hip.y)\n",
        "\n",
        "    # Rule-based classification\n",
        "    if bat_angle < -0.5:\n",
        "        return \"Cover Drive\"\n",
        "    elif bat_angle > 0.5:\n",
        "        return \"Pull Shot\"\n",
        "    elif shoulder_hip_diff < 0.1:\n",
        "        return \"Straight Drive\"\n",
        "    elif left_wrist.y < left_hip.y:\n",
        "        return \"Hook Shot\"\n",
        "    else:\n",
        "        return \"Defensive Shot\"\n",
        "\n",
        "# Process extracted images\n",
        "image_save_folder = \"extracted_images\"  # Update with your folder path\n",
        "# Check if the directory exists, and if not, create it\n",
        "if not os.path.exists(image_save_folder):\n",
        "    os.makedirs(image_save_folder)\n",
        "    print(f\"Directory '{image_save_folder}' created.\")\n",
        "else:\n",
        "    print(f\"Directory '{image_save_folder}' already exists.\")\n",
        "\n",
        "image_files = sorted(os.listdir(image_save_folder))\n",
        "\n",
        "# Store results\n",
        "batting_shots = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_save_folder, image_file)\n",
        "    frame = cv2.imread(image_path)\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Pose detection\n",
        "    results = pose.process(frame_rgb)\n",
        "\n",
        "    if results.pose_landmarks:\n",
        "        # Classify shot\n",
        "        shot_name = classify_shot(results.pose_landmarks.landmark)\n",
        "        batting_shots.append((image_file, shot_name))\n",
        "\n",
        "        # Draw landmarks and shot name\n",
        "        mp.solutions.drawing_utils.draw_landmarks(\n",
        "            frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS\n",
        "        )\n",
        "        cv2.putText(frame, f\"Shot: {shot_name}\", (50, 50),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        # Save annotated frame\n",
        "        output_path = os.path.join(image_save_folder, f\"annotated_{image_file}\")\n",
        "        cv2.imwrite(output_path, frame)\n",
        "    else:\n",
        "        batting_shots.append((image_file, \"No Pose Detected\"))\n",
        "\n",
        "pose.close()\n",
        "\n",
        "# Display results\n",
        "for (image_file, shot_name) in batting_shots[:5]:  # Show first 5 results\n",
        "    image_path = os.path.join(image_save_folder, f\"annotated_{image_file}\")\n",
        "    if os.path.exists(image_path):\n",
        "        image = cv2.imread(image_path)\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"Shot: {shot_name}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No pose detected in {image_file}\")"
      ],
      "metadata": {
        "id": "Rk0KDYali9sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize MediaPipe Pose\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.7)\n",
        "\n",
        "# Define key landmarks\n",
        "LANDMARKS = mp_pose.PoseLandmark\n",
        "\n",
        "def classify_shot(landmarks):\n",
        "    # Extract key joint positions\n",
        "    left_wrist = [landmarks[LANDMARKS.LEFT_WRIST].x, landmarks[LANDMARKS.LEFT_WRIST].y]\n",
        "    right_wrist = [landmarks[LANDMARKS.RIGHT_WRIST].x, landmarks[LANDMARKS.RIGHT_WRIST].y]\n",
        "    left_shoulder = [landmarks[LANDMARKS.LEFT_SHOULDER].x, landmarks[LANDMARKS.LEFT_SHOULDER].y]\n",
        "    right_shoulder = [landmarks[LANDMARKS.RIGHT_SHOULDER].x, landmarks[LANDMARKS.RIGHT_SHOULDER].y]\n",
        "    left_hip = [landmarks[LANDMARKS.LEFT_HIP].x, landmarks[LANDMARKS.LEFT_HIP].y]\n",
        "    right_hip = [landmarks[LANDMARKS.RIGHT_HIP].x, landmarks[LANDMARKS.RIGHT_HIP].y]\n",
        "\n",
        "    # Calculate key metrics\n",
        "    bat_angle = np.arctan2(right_wrist[1] - left_wrist[1], right_wrist[0] - left_wrist[0])\n",
        "    shoulder_hip_alignment = abs(left_shoulder[1] - right_hip[1])\n",
        "    wrist_hip_ratio = left_wrist[1] - left_hip[1]\n",
        "\n",
        "    # Shot classification rules\n",
        "    if bat_angle < -0.8:\n",
        "        return \"Cover Drive\"\n",
        "    elif bat_angle > 0.8:\n",
        "        if wrist_hip_ratio < -0.1:\n",
        "            return \"Pull Shot\"\n",
        "        else:\n",
        "            return \"Hook Shot\"\n",
        "    elif shoulder_hip_alignment < 0.1:\n",
        "        return \"Straight Drive\"\n",
        "    elif abs(bat_angle) < 0.3 and wrist_hip_ratio < -0.15:\n",
        "        return \"Cut Shot\"\n",
        "    elif left_wrist[1] < left_hip[1] and right_wrist[1] < right_hip[1]:\n",
        "        return \"Sweep Shot\"\n",
        "    else:\n",
        "        return \"Defensive Shot\"\n",
        "\n",
        "# Process frames\n",
        "image_folder = \"/content/extracted_images\"  # Path to your extracted frames\n",
        "output_folder = \"/content/annotated_images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "shot_results = []\n",
        "\n",
        "for img_file in sorted(os.listdir(image_folder)):\n",
        "    img_path = os.path.join(image_folder, img_file)\n",
        "    frame = cv2.imread(img_path)\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    results = pose.process(frame_rgb)\n",
        "\n",
        "    if results.pose_landmarks:\n",
        "        # Classify shot\n",
        "        shot_name = classify_shot(results.pose_landmarks.landmark)\n",
        "\n",
        "        # Draw annotations\n",
        "        mp.solutions.drawing_utils.draw_landmarks(\n",
        "            frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
        "            landmark_drawing_spec=mp.solutions.drawing_styles.get_default_pose_landmarks_style()\n",
        "        )\n",
        "\n",
        "        # Add shot name and key lines\n",
        "        cv2.putText(frame, f\"Shot: {shot_name}\", (20, 50),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        # Draw bat angle line\n",
        "        h, w = frame.shape[:2]\n",
        "        cv2.line(frame,\n",
        "                (int(left_wrist[0]*w), int(left_wrist[1]*h)),\n",
        "                (int(right_wrist[0]*w), int(right_wrist[1]*h)),\n",
        "                (0, 0, 255), 3)\n",
        "\n",
        "        # Save and store results\n",
        "        output_path = os.path.join(output_folder, f\"annotated_{img_file}\")\n",
        "        cv2.imwrite(output_path, frame)\n",
        "        shot_results.append((img_file, shot_name))\n",
        "\n",
        "    else:\n",
        "        shot_results.append((img_file, \"No Pose Detected\"))\n",
        "\n",
        "pose.close()\n",
        "\n",
        "# Display results\n",
        "for result in shot_results[:5]:  # Show first 5 results\n",
        "    img_file, shot_name = result\n",
        "    img_path = os.path.join(output_folder, f\"annotated_{img_file}\")\n",
        "\n",
        "    if os.path.exists(img_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"Detected Shot: {shot_name}\", fontsize=14)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"Could not process: {img_file}\")"
      ],
      "metadata": {
        "id": "Iuuc2B5cQKdb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}